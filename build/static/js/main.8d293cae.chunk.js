(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{354:function(e,t,n){"use strict";n.r(t);var a=n(0),l=n.n(a),r=n(42),i=n.n(r),o=(n(61),n(3)),c=n(2),s=(n(62),n(13)),m=(n(65),n(41));var u=e=>{let{children:t}=e;return l.a.createElement("div",{style:{margin:"20px"}},l.a.createElement("header",{style:{marginBottom:"20px",borderBottom:"2px solid #ccc"}},l.a.createElement("h1",null,"Academic Topics"),l.a.createElement("nav",{style:{paddingBottom:"10px",borderBottom:"2px solid black"}}," ",l.a.createElement(o.b,{to:"/",style:{marginRight:"10px"}},"Home"),l.a.createElement(o.b,{to:"/research",style:{marginRight:"10px"}},"Research"),l.a.createElement(o.b,{to:"/algorithm",style:{marginRight:"10px"}},"Algorithm"),l.a.createElement(o.b,{to:"/physics",style:{marginRight:"10px"}},"Physics"),l.a.createElement(o.b,{to:"/machine-learning",style:{marginRight:"10px"}},"Data Science and ML"),l.a.createElement(o.b,{to:"/Coding",style:{marginRight:"10px"}},"Coding Techniques"),l.a.createElement(o.b,{to:"/Reference",style:{marginRight:"10px"}},"Reference"))),l.a.createElement("main",null,t),l.a.createElement("footer",{style:{marginTop:"20px"}},l.a.createElement("p",null,"\xa9 2024 Dowling Wong. All rights reserved")))};const h='\nclass PID:\n    def __init__(self, Kp, Ki, Kd, setpoint):\n        self.Kp = Kp\n        self.Ki = Ki\n        self.Kd = Kd\n        self.setpoint = setpoint\n        self.integral = 0\n        self.previous_error = 0\n\n    def update(self, measured_value, dt):\n        # Calculate error\n        error = self.setpoint - measured_value\n        \n        # Proportional term\n        P_out = self.Kp * error\n        \n        # Integral term\n        self.integral += error * dt\n        I_out = self.Ki * self.integral\n        \n        # Derivative term\n        derivative = (error - self.previous_error) / dt\n        D_out = self.Kd * derivative\n        \n        # Total output\n        output = P_out + I_out + D_out\n        \n        # Save error for next iteration\n        self.previous_error = error\n        \n        return output\n\n# Example usage\nimport time\n\n# PID controller with Kp=1.0, Ki=0.1, Kd=0.05, and setpoint=10\npid = PID(Kp=1.0, Ki=0.1, Kd=0.05, setpoint=10)\n\n# Simulate a process variable (e.g., temperature)\nmeasured_value = 0\ndt = 0.1  # time step in seconds\n\nfor i in range(100):\n    control_output = pid.update(measured_value, dt)\n    # Simulate process reaction to control output (for example purposes only)\n    measured_value += control_output * dt\n    print(f"Time: {i*dt:.1f}s, Measured Value: {measured_value:.2f}, Control Output: {control_output:.2f}")\n    time.sleep(dt)\n  ';var d=function(){return l.a.createElement("main",null,l.a.createElement("h2",null,"PID Control Explanation"),l.a.createElement("h3",null,"Proportional-Integral-Derivative Control"),l.a.createElement("p",null,l.a.createElement("strong",null,"Proportional Term (P):")),l.a.createElement("ul",null,l.a.createElement("li",null,"The proportional term produces an output value that is proportional to the current error value."),l.a.createElement("li",null,"The proportional response can be adjusted by multiplying the error by a constant ",l.a.createElement(s.InlineMath,{math:"K_p"}),", known as the proportional gain."),l.a.createElement("li",null,"If the error is large, the control output is large, and vice versa.")),l.a.createElement("p",null,l.a.createElement("strong",null,"Integral Term (I):")),l.a.createElement("ul",null,l.a.createElement("li",null,"The integral term is concerned with the accumulation of past errors."),l.a.createElement("li",null,"If the error has been present for some time, the integral term will accumulate and attempt to correct the error."),l.a.createElement("li",null,"This term is multiplied by a constant ",l.a.createElement(s.InlineMath,{math:"K_i"}),", the integral gain.")),l.a.createElement("p",null,l.a.createElement("strong",null,"Derivative Term (D):")),l.a.createElement("ul",null,l.a.createElement("li",null,"The derivative term predicts future error based on its rate of change."),l.a.createElement("li",null,"By looking at the rate of change of the error, it applies a damping effect, which reduces the overshoot."),l.a.createElement("li",null,"This term is multiplied by a constant ",l.a.createElement(s.InlineMath,{math:"K_d"}),", the derivative gain.")),l.a.createElement("h3",null,"PID Control Algorithm"),l.a.createElement("p",null,"The PID control algorithm can be represented as:"),l.a.createElement(s.BlockMath,{math:"output(t) = K_p \\cdot e(t) + K_i \\cdot \\int_0^t e(\\tau) \\, d\\tau + K_d \\cdot \\frac{d e(t)}{d t}"}),l.a.createElement("p",null,"where:"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(s.InlineMath,{math:"e(t)"})," is the error at time ",l.a.createElement(s.InlineMath,{math:"t"}),"."),l.a.createElement("li",null,l.a.createElement(s.InlineMath,{math:"K_p"})," is the proportional gain."),l.a.createElement("li",null,l.a.createElement(s.InlineMath,{math:"K_i"})," is the integral gain."),l.a.createElement("li",null,l.a.createElement(s.InlineMath,{math:"K_d"})," is the derivative gain.")),l.a.createElement("h3",null,"Python Implementation"),l.a.createElement(m.a,{language:"python"},h))};var p=function(){return l.a.createElement("main",null,"Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. The core principle behind these methods is to use randomness to solve problems that might be deterministic in principle. They are especially useful for problems involving high-dimensional integrals, optimization, and probabilistic analysis.",l.a.createElement("b",null,"General Mathematical Definition:"),"Let X be a random variable with a known probability distribution P. Monte Carlo methods estimate the expected value or other properties of X by performing the following steps:",l.a.createElement("ol",null,l.a.createElement("li",null,l.a.createElement("b",null,"Random Sampling:")," Generate a large number of independent and identically distributed (i.i.d.) samples X",l.a.createElement("sub",null,"1"),", X",l.a.createElement("sub",null,"2"),", ..., X",l.a.createElement("sub",null,"n")," from the probability distribution P."),l.a.createElement("li",null,l.a.createElement("b",null,"Function Evaluation:")," Evaluate the function of interest f(X) for each sample to obtain f(X",l.a.createElement("sub",null,"1"),"), f(X",l.a.createElement("sub",null,"2"),"), ..., f(X",l.a.createElement("sub",null,"n"),")."),l.a.createElement("li",null,l.a.createElement("b",null,"Averaging:")," Compute the average of the function values to estimate the expected value E[f(X)]:",l.a.createElement("div",null,"E[f(X)] = (1/n) \u2211",l.a.createElement("sub",null,"i=1"),l.a.createElement("sup",null,"n")," f(X",l.a.createElement("sub",null,"i"),")"))),l.a.createElement("b",null,"Example: Estimating an Integral"),"Monte Carlo methods are often used to estimate the value of integrals, especially in higher dimensions. Consider the integral of a function f(x) over a domain D:",l.a.createElement("div",null,"I = \u222b",l.a.createElement("sub",null,"D")," f(x) dx"),"The Monte Carlo estimate of this integral is obtained as follows:",l.a.createElement("ol",null,l.a.createElement("li",null,l.a.createElement("b",null,"Uniform Sampling:")," Generate n random samples X",l.a.createElement("sub",null,"1"),", X",l.a.createElement("sub",null,"2"),", ..., X",l.a.createElement("sub",null,"n")," uniformly distributed over the domain D."),l.a.createElement("li",null,l.a.createElement("b",null,"Function Evaluation:")," Evaluate the function f at each sample point X",l.a.createElement("sub",null,"i"),"."),l.a.createElement("li",null,l.a.createElement("b",null,"Estimate the Integral:"),l.a.createElement("div",null,"&hat;I = (Volume of D / n) \u2211",l.a.createElement("sub",null,"i=1"),l.a.createElement("sup",null,"n")," f(X",l.a.createElement("sub",null,"i"),")"))),"Here, the volume of D is a scaling factor to account for the domain over which the function is integrated.",l.a.createElement("b",null,"Convergence and Error"),"The law of large numbers ensures that the Monte Carlo estimate converges to the true expected value or integral as the number of samples n increases:",l.a.createElement("div",null,"&hat;E[f(X)] \u2192 E[f(X)] as n \u2192 \u221e"),"The central limit theorem provides a measure of the error in the Monte Carlo estimate, indicating that the error decreases as O(1/\u221an). This means that the standard deviation of the estimate decreases with the square root of the number of samples.",l.a.createElement("b",null,"Key Properties"),l.a.createElement("ol",null,l.a.createElement("li",null,l.a.createElement("b",null,"Probabilistic Convergence:")," The accuracy of the Monte Carlo estimate improves with an increasing number of samples."),l.a.createElement("li",null,l.a.createElement("b",null,"Dimensional Independence:")," Monte Carlo methods are less affected by the dimensionality of the problem compared to deterministic methods."),l.a.createElement("li",null,l.a.createElement("b",null,"Versatility:")," They can be applied to a wide range of problems, including those with complex geometries and constraints.")),l.a.createElement("b",null,"Applications"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement("b",null,"Physics:")," Simulation of particle interactions and statistical mechanics."),l.a.createElement("li",null,l.a.createElement("b",null,"Finance:")," Option pricing and risk analysis."),l.a.createElement("li",null,l.a.createElement("b",null,"Engineering:")," Reliability analysis and optimization."),l.a.createElement("li",null,l.a.createElement("b",null,"Computer Graphics:")," Rendering and global illumination.")),l.a.createElement("b",null,"Summary"),"Monte Carlo methods use random sampling to estimate mathematical quantities that are otherwise difficult to compute deterministically. By leveraging the properties of random variables and statistical analysis, these methods provide powerful tools for numerical integration, optimization, and probabilistic modeling across various scientific and engineering disciplines.")};const E=l.a.createElement("main",null,l.a.createElement("h2",null,"Kmeans by SKlearn"),l.a.createElement(s.BlockMath,{math:"c = \\\\pm\\\\sqrt{a^2 + b^2}"}),l.a.createElement(m.a,{language:"python"},"import numpy as np\n          from sklearn.cluster import KMeans\n          X = np.array([[1, 2], [1, 4], [1, 0],\n                        [10, 2], [10, 4], [10, 0]])\n          kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n          print(kmeans.labels_)\n          "),l.a.createElement("hr",null),l.a.createElement("h2",null,"MonteCarlo"),l.a.createElement(o.b,{to:"/MonteCarlo",style:{marginRight:"10px"}},"MonteCarlo"),l.a.createElement("hr",null),l.a.createElement("h2",null,"DarkQuest"),l.a.createElement(m.a,{language:"cpp"},'#include <iostream>\n          int main() {\n            std::cout << "Hello, World!";\n            return 0;\n          }\n          '),l.a.createElement("hr",null),l.a.createElement("h2",null,"Support Vector Machine by SKlearn"),l.a.createElement("hr",null),l.a.createElement("h2",null,"PID control"),l.a.createElement(o.b,{to:"/PID",style:{marginRight:"10px"}},"PID control"));var g=function(){return E};var f=function(){return l.a.createElement("div",null,l.a.createElement("h1",null,"This is the Physics page."),l.a.createElement("div",{style:{display:"flex",justifyContent:"center",alignItems:"center",height:"100vh"}},l.a.createElement("div",{style:{height:"750px",width:"50%",border:"1px solid rgba(0, 0, 0, 0.3)"}},l.a.createElement("iframe",{src:"/nutshell_formula.pdf",width:"100%",height:"100%",style:{border:"none"},title:"PDF Viewer"}))))};var b=function(){return l.a.createElement("main",null,l.a.createElement("h2",null,"Generative Adversarial Network (GAN) Example"),l.a.createElement("p",null,"Generative Adversarial Networks (GANs) consist of two models, a generator and a discriminator, which are trained simultaneously in a zero-sum game framework. The generator's role is to create data that looks as close as possible to real data, while the discriminator tries to distinguish between real and generated data. Here are the key steps involved:"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement("strong",null,"Select Data:")," Choose the type of data you want the GAN to generate. This could be images, text, music, etc."),l.a.createElement("li",null,l.a.createElement("strong",null,"Prepare Models:")," Design and initialize the generator and discriminator models with appropriate architectures."),l.a.createElement("li",null,l.a.createElement("strong",null,"Train Models:")," Alternately train the discriminator and generator. The discriminator learns to differentiate real data from fake, and the generator learns to fool the discriminator."),l.a.createElement("li",null,l.a.createElement("strong",null,"Evaluate:")," Regularly evaluate the generator's output and adjust parameters or model architecture as needed."),l.a.createElement("li",null,l.a.createElement("strong",null,"Generate Data:")," Once trained, use the generator to create data. This data can be used for various applications such as art, music, or as training data for other models.")),l.a.createElement(m.a,{language:"python"},"import tensorflow as tf\n      from tensorflow.keras import layers\n\n      # Generator Model\n      def create_generator():\n          model = tf.keras.Sequential([\n              layers.Dense(256, use_bias=False, input_shape=(100,)),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(512),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(784, activation='tanh'),\n              layers.Reshape((28, 28, 1))\n          ])\n          return model\n\n      # Discriminator Model\n      def create_discriminator():\n          model = tf.keras.Sequential([\n              layers.Flatten(input_shape=(28, 28, 1)),\n              layers.Dense(512),\n              layers.LeakyReLU(),\n              layers.Dropout(0.3),\n              layers.Dense(1)\n          ])\n          return model\n\n      # Compile and set up the GAN\n      generator = create_generator()\n      discriminator = create_discriminator()\n\n      discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n      # The generator is trained through the combined model where it tries to deceive the discriminator\n      combined = tf.keras.Sequential([generator, discriminator])\n      combined.compile(optimizer='adam', loss='binary_crossentropy')\n\n      def train(generator, discriminator, combined, epochs, batch_size):\n          for epoch in range(epochs):\n              # Here, you would include the steps to train your models.\n              # This typically involves generating noise, creating fake images from the noise using the generator,\n              # passing real and fake images to the discriminator, and adjusting the weights based on their performance.\n              pass\n\n      # Example of calling the train function\n      # train(generator, discriminator, combined, epochs=50, batch_size=32)"),l.a.createElement(m.a,{language:"python"},"import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_website(url):\n    # Send a HTTP request to the specified URL\n    response = requests.get(url)\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Parse the content of the request with BeautifulSoup\n        soup = BeautifulSoup(response.text, 'html.parser')\n        # Extract elements as needed, here we take an example of extracting all paragraph tags\n        paragraphs = soup.find_all('p')\n        for p in paragraphs:\n            print(p.text)\n    else:\n        print(\"Failed to retrieve the website\")\n\n# Example URL to scrape\nscrape_website('http://example.com')"),l.a.createElement("hr",null))};var y=function(){return l.a.createElement("main",null,l.a.createElement("h2",null,"Key Concepts"),l.a.createElement("h3",null,"1. Vector Databases"),l.a.createElement("ul",null,l.a.createElement("li",null,"Emerged due to limitations in traditional databases and the rise of AI applications."),l.a.createElement("li",null,"Store and manage vector embeddings which represent data in high-dimensional spaces.")),l.a.createElement("h3",null,"2. Vector Embeddings"),l.a.createElement("ul",null,l.a.createElement("li",null,"Process of converting data (text, images, audio) into high-dimensional vectors."),l.a.createElement("li",null,"Examples include OpenAI's text-embedding-ada-002 for text and clip-vit-base-patch32 for images.")),l.a.createElement("h3",null,"3. Similarity Search"),l.a.createElement("ul",null,l.a.createElement("li",null,"Core function of vector databases, finding similar vectors in high-dimensional space."),l.a.createElement("li",null,"Algorithms include K-Means, Product Quantization (PQ), Hierarchical Navigable Small Worlds (HNSW), and Locality Sensitive Hashing (LSH).")),l.a.createElement("h3",null,"4. Feature Engineering"),l.a.createElement("ul",null,l.a.createElement("li",null,"Process of extracting features from raw data to better represent its underlying patterns."),l.a.createElement("li",null,"Essential for creating effective vector embeddings.")),l.a.createElement("h2",null,"Important Algorithms and Methods"),l.a.createElement("h3",null,"1. K-Means Clustering"),l.a.createElement("ul",null,l.a.createElement("li",null,"Divides data into k clusters by minimizing within-cluster variance."),l.a.createElement("li",null,"Steps: initialize centroids, assign points to nearest centroid, update centroids, repeat until convergence.")),l.a.createElement("h3",null,"2. Product Quantization (PQ)"),l.a.createElement("ul",null,l.a.createElement("li",null,"Reduces memory usage by splitting vectors into sub-vectors and quantizing each sub-vector independently."),l.a.createElement("li",null,"Maintains search efficiency by encoding vectors into compact representations.")),l.a.createElement("h3",null,"3. Hierarchical Navigable Small Worlds (HNSW)"),l.a.createElement("ul",null,l.a.createElement("li",null,"Constructs a multi-layer graph where each layer is a small-world network."),l.a.createElement("li",null,"Provides efficient search by navigating through higher layers (coarse search) down to lower layers (fine search).")),l.a.createElement("h3",null,"4. Locality Sensitive Hashing (LSH)"),l.a.createElement("ul",null,l.a.createElement("li",null,"Hashes similar vectors into the same bucket with high probability."),l.a.createElement("li",null,"Uses random projections to map high-dimensional data into low-dimensional hash buckets for quick comparison.")),l.a.createElement("h2",null,"Similarity Measurements"),l.a.createElement("h3",null,"1. Euclidean Distance"),l.a.createElement("p",null,l.a.createElement("code",null,"d(A, B) = \u221a(\u03a3(A_i - B_i)^2)")),l.a.createElement("ul",null,l.a.createElement("li",null,"Measures the straight-line distance between two points in Euclidean space.")),l.a.createElement("h3",null,"2. Cosine Similarity"),l.a.createElement("p",null,l.a.createElement("code",null,"cos(\u03b8) = (A \xb7 B) / (||A|| ||B||)")),l.a.createElement("ul",null,l.a.createElement("li",null,"Measures the cosine of the angle between two vectors, focusing on direction rather than magnitude.")),l.a.createElement("h3",null,"3. Dot Product Similarity"),l.a.createElement("p",null,l.a.createElement("code",null,"A \xb7 B = \u03a3(A_i * B_i)")),l.a.createElement("ul",null,l.a.createElement("li",null,"Simple and efficient, combines magnitude and direction of vectors.")),l.a.createElement("h2",null,"Filtering"),l.a.createElement("ul",null,l.a.createElement("li",null,"Combines vector and metadata indexing to refine search results."),l.a.createElement("li",null,"Can be pre-filtering (before similarity search) or post-filtering (after similarity search).")),l.a.createElement("h2",null,"Selection of Vector Databases"),l.a.createElement("ul",null,l.a.createElement("li",null,"Factors include distributed architecture, high availability, fault tolerance, access control, and integration with existing APIs and SDKs."),l.a.createElement("li",null,"Examples of vector databases: Chroma, Milvus, Pinecone, Qdrant, Typesense, Weaviate.")),l.a.createElement("h2",null,"Conclusion"),l.a.createElement("ul",null,l.a.createElement("li",null,"Vector databases are pivotal in AI and machine learning applications, offering efficient similarity search in high-dimensional spaces."),l.a.createElement("li",null,"They require careful selection and implementation based on the specific needs of the application and the characteristics of the data.")))};var v=function(){return l.a.createElement("div",null,l.a.createElement("h1",null,"Data Science and Machine Learning"),l.a.createElement("main",null,l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Regression"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Clustering"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Descision Tree"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Random Forest"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Neural Network"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Naive Bayes classifier"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Support Vector Machine"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++.")),l.a.createElement("h2",null,"Data Acquision"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"/DAQ",style:{marginRight:"10px"}},l.a.createElement("strong",null,"DAQ")," ")," Comprehansive introduction for C++.")),l.a.createElement("h2",null,"VectorDatabase"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"/VectorDatabase",style:{marginRight:"10px"}},l.a.createElement("strong",null,"Vector Database")," ")," Comprehansive introduction for C++."))))};var w=function(){return l.a.createElement("div",null,"This is the Coding Techniques page.",l.a.createElement("h2",null,"Calling Async Functions in Threads in Python"),l.a.createElement("p",null,"Running asynchronous functions in threads can significantly enhance the efficiency of Python applications, especially those that require concurrent execution without blocking the main execution thread. This technique is particularly useful in scenarios where you need to perform I/O-bound or network-bound tasks asynchronously within a traditionally synchronous Python application."),l.a.createElement("p",null,"In the provided Python example, we first define a function ",l.a.createElement("code",null,"start_async_loop")," that sets up and runs an asyncio event loop within a new thread. The ",l.a.createElement("code",null,"async_task")," function demonstrates an asynchronous task, in this case, a simple operation that mimics a delay using ",l.a.createElement("code",null,"asyncio.sleep"),". We then define ",l.a.createElement("code",null,"run_async_in_thread"),", which initializes a new event loop, starts a thread with that loop, and safely schedules the asynchronous task to be run on this separate thread."),l.a.createElement("p",null,"This setup allows the asynchronous code to run independently of the main program's flow, enabling tasks to be handled in the background without interruption. It's an effective strategy for integrating asynchronous programming patterns into applications that are not inherently asynchronous, thereby improving performance and responsiveness."),l.a.createElement(s.BlockMath,{math:"f(x) = x^{2} + 2x + 1"}),l.a.createElement(m.a,{language:"python"},'\n      import asyncio\n      import threading\n      def start_async_loop(loop):\n      asyncio.set_event_loop(loop)\n      loop.run_forever()\n\n      async def async_task():\n      print("Task Start")\n      await asyncio.sleep(1)\n      print("Task Complete")\n\n      def run_async_in_thread():\n      new_loop = asyncio.new_event_loop()\n      t = threading.Thread(target=start_async_loop, args=(new_loop,))\n      t.start()\n      asyncio.run_coroutine_threadsafe(async_task(), new_loop)\n\n      Execute the function to run async task in a new thread\n      run_async_in_thread()'))};var _=function(){return l.a.createElement("div",null,l.a.createElement("h1",null,"References for the note pages"),l.a.createElement("main",null,l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Coding Techniques"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/zh-cn/01-intro/"},l.a.createElement("strong",null,"Modern C++:")," ")," Comprehansive introduction for C++."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://changkun.de/modern-cpp/en-us/00-preface/"},l.a.createElement("strong",null,"C-extension in Python:")," ")," From Python cookbook, Chinese translation hosted on github."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://docs.python.org/zh-cn/3/library/asyncio-task.html#coroutines"},l.a.createElement("strong",null,"Coroutines and Tasks:")," ")," Official Python documentation on coroutines and threads."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://cppyy.readthedocs.io/en/latest/"},l.a.createElement("strong",null,"cppyy:")," ")," Automatic Python-C++ bindings."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://rpucella.net/courses/webdev-sp24/"},l.a.createElement("strong",null,"Full-stack web development:")," ")," React, flask, and WebAssembly."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://docs.python.org/3/c-api/memory.html"},l.a.createElement("strong",null,"Python Memory Management:")," ")," Automatic Python-C++ bindings.")),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Data Science, Statistics and Machine Learning"),l.a.createElement("ul",null,l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://jduarte.physics.ucsd.edu/phys139_239/README.html"},l.a.createElement("strong",null,"Machine Learning in Physics:")," ")," UCSD PHYS 139/239, By Javier Duart."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://theoryandpractice.org/stats-ds-book/intro.html"},l.a.createElement("strong",null,"Statistics and Data Science:")," ")," NYU Physics titled Statistics and Data Science. Interactive Jupyter book."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://github.com/mit-physics-data/lectures"},l.a.createElement("strong",null,"8.316 Data Science in Physics:")," ")," @MIT, by Phil Harris."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://jduarte.physics.ucsd.edu/capstone-particle-physics-domain/README.html"},l.a.createElement("strong",null,"Particle Physics and Machine Learning:")," ")," Developed by Javier Duarte,  Frank W\xfcrthwein."),l.a.createElement("li",{style:{marginBottom:"10px"}},l.a.createElement(o.b,{to:"https://jduarte.physics.ucsd.edu/iaifi-summer-school/intro.html"},l.a.createElement("strong",null,"IAIFI Summer School Tutorials")," ")," Model compression, ML in particle physics. By Javier Duart, Dylan Rankins, Patrick McCormack."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://www.nbi.dk/~koskinen/Teaching/AdvancedMethodsInAppliedStatistics2018/AdvancedMethodsAppliedStatistics2018.html"},l.a.createElement("strong",null,"Advanced Methods in Applied Statistics 2018:")," ")," BDTs, MultiNest bayesian, Markov Chain Monte Carlo, Likelihood."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://github.com/jeffheaton/t81_558_deep_learning"},l.a.createElement("strong",null,"Keras-Applications of Deep Neural Networks @WUSTL:")," ")," React, flask, and WebAssembly."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://guangzhengli.com/blog/zh/vector-database/"},l.a.createElement("strong",null,"Vector Database:")," ")," Vector store, similarity search/measurement, filtering."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://github.com/pgvector/pgvector"},l.a.createElement("strong",null,"PGVector:")," ")," Open-source vector similarity search for Postgres."),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://github.com/Denis2054/Transformers-for-NLP-and-Computer-Vision-3rd-Edition"},l.a.createElement("strong",null,"Transformers for Natural Language Processing and Computer Vision")," ")," Take Generative AI and LLMs to the next level with Hugging Face, Google Vertex AI, ChatGPT, GPT-4V, and DALL-E 3 3rd Edition"),l.a.createElement("li",null,l.a.createElement(o.b,{to:"https://github.com/MalayAgr/generative-ai-with-llms-notes?tab=readme-ov-file"},l.a.createElement("strong",null,"Generative AI with LLM, Notes")," ")," Notes for the course Generative AI With Large Language Models."))))};var k=function(){return l.a.createElement("main",null,l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"DELight"),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"Silicon Modules at CMS"),l.a.createElement("hr",null)," ",l.a.createElement("h2",null,"DarkQuest"))};var x=function(){return l.a.createElement("main",null,l.a.createElement("hr",null),l.a.createElement("h2",null,"Kmeans by SKlearn"),l.a.createElement(s.BlockMath,{math:"c = \\\\pm\\\\sqrt{a^2 + b^2}"}),l.a.createElement(m.a,{language:"python"},"import numpy as np\n          from sklearn.cluster import KMeans\n          X = np.array([[1, 2], [1, 4], [1, 0],\n                        [10, 2], [10, 4], [10, 0]])\n          kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n          print(kmeans.labels_)\n          "),l.a.createElement("hr",null),l.a.createElement("h2",null,"Gradient descent"),l.a.createElement(s.BlockMath,{math:"\\\\mathbf{x}_{\\\\text{new}} = \\\\mathbf{x} - \\\\eta \\\\nabla f(\\\\mathbf{x})"}),l.a.createElement(m.a,{language:"python"},"import numpy as np\n          def gradient_descent(x, grad, eta=0.01, n_iter=100):\n            for _ in range(n_iter):\n              x -= eta * grad(x)\n            return x\n          "),l.a.createElement("hr",null),l.a.createElement("h2",null,"Newton's Method for Optimization"),l.a.createElement("p",null,"Newton's method, also known as the Newton-Raphson method, is an advanced optimization technique that uses second-order information to find the minima of a function more efficiently compared to first-order methods like gradient descent. This method not only considers the gradient (first derivatives) but also the curvature of the function via the Hessian (second derivatives), allowing for adaptive step sizes and faster convergence."),l.a.createElement("p",null,"Here\u2019s how Newton's step works in the context of optimization:",l.a.createElement("ol",null,l.a.createElement("li",null,l.a.createElement("strong",null,"Objective Function"),": You have a function you want to minimize."),l.a.createElement("li",null,l.a.createElement("strong",null,"Gradient and Hessian"),": Compute the gradient and the Hessian matrix."),l.a.createElement("li",null,l.a.createElement("strong",null,"Newton's Update Rule"),": Update the parameters using both the gradient and the inverse of the Hessian."),l.a.createElement("li",null,l.a.createElement("strong",null,"Convergence"),": Repeat until the change is small, indicating proximity to a minimum."))),l.a.createElement(s.BlockMath,{math:"\\\\mathbf{x}_{\\\\text{new}} = \\\\mathbf{x} - H(\\\\mathbf{x})^{-1} \\\\nabla f(\\\\mathbf{x})"}),l.a.createElement(m.a,{language:"python"},"def newtons_method(f, df, ddf, x0, tol=1e-5, max_iter=50):\n            x = x0\n            for _ in range(max_iter):\n                H_inv = np.linalg.inv(ddf(x))\n                x_new = x - H_inv @ df(x)\n                if np.linalg.norm(x_new - x) < tol:\n                    break\n                x = x_new\n            return x\n          "),l.a.createElement("hr",null),l.a.createElement("h2",null,"DarkQuest"),l.a.createElement(m.a,{language:"cpp"},'#include <iostream>\n          int main() {\n            std::cout << "Hello, World!";\n            return 0;\n          }\n          '),l.a.createElement("hr",null),l.a.createElement("h2",null,"Support Vector Machine by SKlearn"),l.a.createElement("hr",null))};var C=function(){return l.a.createElement(o.a,null,l.a.createElement(u,null,l.a.createElement(c.c,null,l.a.createElement(c.a,{path:"/research",element:l.a.createElement(k,null)}),l.a.createElement(c.a,{path:"/algorithm",element:l.a.createElement(g,null)}),l.a.createElement(c.a,{path:"/physics",element:l.a.createElement(f,null)}),l.a.createElement(c.a,{path:"/machine-learning",element:l.a.createElement(v,null)}),l.a.createElement(c.a,{path:"/coding",element:l.a.createElement(w,null)}),l.a.createElement(c.a,{path:"/reference",element:l.a.createElement(_,null)}),l.a.createElement(c.a,{path:"/GradientDescent",element:l.a.createElement(x,null)}),l.a.createElement(c.a,{path:"/MonteCarlo",element:l.a.createElement(p,null)}),l.a.createElement(c.a,{path:"/PID",element:l.a.createElement(d,null)}),l.a.createElement(c.a,{path:"/DAQ",element:l.a.createElement(b,null)}),l.a.createElement(c.a,{path:"/VectorDatabase",element:l.a.createElement(y,null)}),l.a.createElement(c.a,{path:"/",element:l.a.createElement("div",null,"Welcome to the Academic Notes",l.a.createElement("br",null),l.a.createElement("a",{href:"ref/index.html",target:"_blank",rel:"noopener noreferrer"},"Redirect to Dowling's library of books and papers"),l.a.createElement("br",null),l.a.createElement("a",{href:"py501/index.html",target:"_blank",rel:"noopener noreferrer"},"Redirect to mirror of py501 mathematical physics"))}))))};var M=e=>{e&&e instanceof Function&&n.e(3).then(n.bind(null,355)).then(t=>{let{getCLS:n,getFID:a,getFCP:l,getLCP:r,getTTFB:i}=t;n(e),a(e),l(e),r(e),i(e)})};i.a.createRoot(document.getElementById("root")).render(l.a.createElement(l.a.StrictMode,null,l.a.createElement(C,null))),M()},53:function(e,t,n){e.exports=n(354)},61:function(e,t,n){}},[[53,1,2]]]);
//# sourceMappingURL=main.8d293cae.chunk.js.map