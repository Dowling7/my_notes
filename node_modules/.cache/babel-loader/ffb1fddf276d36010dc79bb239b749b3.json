{"ast":null,"code":"var _jsxFileName = \"/Users/wongdowling/Documents/my_notes/src/subsections/MachineLearning/DAQ.js\";\nimport React from \"react\";\nimport Layout, { InlineMath, BlockMath, SyntaxHighlighter } from \"../../Layout\";\nfunction DAQ() {\n  return /*#__PURE__*/React.createElement(\"main\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"h2\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 7,\n      columnNumber: 7\n    }\n  }, \"Generative Adversarial Network (GAN) Example\"), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 7\n    }\n  }, \"Generative Adversarial Networks (GANs) consist of two models, a generator and a discriminator, which are trained simultaneously in a zero-sum game framework. The generator's role is to create data that looks as close as possible to real data, while the discriminator tries to distinguish between real and generated data. Here are the key steps involved:\"), /*#__PURE__*/React.createElement(\"ul\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"li\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 10,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"strong\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 10,\n      columnNumber: 13\n    }\n  }, \"Select Data:\"), \" Choose the type of data you want the GAN to generate. This could be images, text, music, etc.\"), /*#__PURE__*/React.createElement(\"li\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"strong\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 13\n    }\n  }, \"Prepare Models:\"), \" Design and initialize the generator and discriminator models with appropriate architectures.\"), /*#__PURE__*/React.createElement(\"li\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"strong\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 12,\n      columnNumber: 13\n    }\n  }, \"Train Models:\"), \" Alternately train the discriminator and generator. The discriminator learns to differentiate real data from fake, and the generator learns to fool the discriminator.\"), /*#__PURE__*/React.createElement(\"li\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 13,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"strong\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 13,\n      columnNumber: 13\n    }\n  }, \"Evaluate:\"), \" Regularly evaluate the generator's output and adjust parameters or model architecture as needed.\"), /*#__PURE__*/React.createElement(\"li\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"strong\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 13\n    }\n  }, \"Generate Data:\"), \" Once trained, use the generator to create data. This data can be used for various applications such as art, music, or as training data for other models.\")), /*#__PURE__*/React.createElement(SyntaxHighlighter, {\n    language: \"python\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 16,\n      columnNumber: 7\n    }\n  }, `import tensorflow as tf\n      from tensorflow.keras import layers\n\n      # Generator Model\n      def create_generator():\n          model = tf.keras.Sequential([\n              layers.Dense(256, use_bias=False, input_shape=(100,)),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(512),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(784, activation='tanh'),\n              layers.Reshape((28, 28, 1))\n          ])\n          return model\n\n      # Discriminator Model\n      def create_discriminator():\n          model = tf.keras.Sequential([\n              layers.Flatten(input_shape=(28, 28, 1)),\n              layers.Dense(512),\n              layers.LeakyReLU(),\n              layers.Dropout(0.3),\n              layers.Dense(1)\n          ])\n          return model\n\n      # Compile and set up the GAN\n      generator = create_generator()\n      discriminator = create_discriminator()\n\n      discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n      # The generator is trained through the combined model where it tries to deceive the discriminator\n      combined = tf.keras.Sequential([generator, discriminator])\n      combined.compile(optimizer='adam', loss='binary_crossentropy')\n\n      def train(generator, discriminator, combined, epochs, batch_size):\n          for epoch in range(epochs):\n              # Here, you would include the steps to train your models.\n              # This typically involves generating noise, creating fake images from the noise using the generator,\n              # passing real and fake images to the discriminator, and adjusting the weights based on their performance.\n              pass\n\n      # Example of calling the train function\n      # train(generator, discriminator, combined, epochs=50, batch_size=32)`), /*#__PURE__*/React.createElement(SyntaxHighlighter, {\n    language: \"python\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 64,\n      columnNumber: 1\n    }\n  }, `import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_website(url):\n    # Send a HTTP request to the specified URL\n    response = requests.get(url)\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Parse the content of the request with BeautifulSoup\n        soup = BeautifulSoup(response.text, 'html.parser')\n        # Extract elements as needed, here we take an example of extracting all paragraph tags\n        paragraphs = soup.find_all('p')\n        for p in paragraphs:\n            print(p.text)\n    else:\n        print(\"Failed to retrieve the website\")\n\n# Example URL to scrape\nscrape_website('http://example.com')`), /*#__PURE__*/React.createElement(\"hr\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 87,\n      columnNumber: 7\n    }\n  }));\n}\nexport default DAQ;","map":{"version":3,"names":["React","Layout","InlineMath","BlockMath","SyntaxHighlighter","DAQ","createElement","__self","__source","fileName","_jsxFileName","lineNumber","columnNumber","language"],"sources":["/Users/wongdowling/Documents/my_notes/src/subsections/MachineLearning/DAQ.js"],"sourcesContent":["import React from \"react\";\nimport Layout, { InlineMath, BlockMath, SyntaxHighlighter } from \"../../Layout\";\n\nfunction DAQ() {\n  return (\n    <main>\n      <h2>Generative Adversarial Network (GAN) Example</h2>\n      <p>Generative Adversarial Networks (GANs) consist of two models, a generator and a discriminator, which are trained simultaneously in a zero-sum game framework. The generator's role is to create data that looks as close as possible to real data, while the discriminator tries to distinguish between real and generated data. Here are the key steps involved:</p>\n      <ul>\n        <li><strong>Select Data:</strong> Choose the type of data you want the GAN to generate. This could be images, text, music, etc.</li>\n        <li><strong>Prepare Models:</strong> Design and initialize the generator and discriminator models with appropriate architectures.</li>\n        <li><strong>Train Models:</strong> Alternately train the discriminator and generator. The discriminator learns to differentiate real data from fake, and the generator learns to fool the discriminator.</li>\n        <li><strong>Evaluate:</strong> Regularly evaluate the generator's output and adjust parameters or model architecture as needed.</li>\n        <li><strong>Generate Data:</strong> Once trained, use the generator to create data. This data can be used for various applications such as art, music, or as training data for other models.</li>\n      </ul>\n      <SyntaxHighlighter language=\"python\">\n      {`import tensorflow as tf\n      from tensorflow.keras import layers\n\n      # Generator Model\n      def create_generator():\n          model = tf.keras.Sequential([\n              layers.Dense(256, use_bias=False, input_shape=(100,)),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(512),\n              layers.BatchNormalization(),\n              layers.LeakyReLU(),\n              layers.Dense(784, activation='tanh'),\n              layers.Reshape((28, 28, 1))\n          ])\n          return model\n\n      # Discriminator Model\n      def create_discriminator():\n          model = tf.keras.Sequential([\n              layers.Flatten(input_shape=(28, 28, 1)),\n              layers.Dense(512),\n              layers.LeakyReLU(),\n              layers.Dropout(0.3),\n              layers.Dense(1)\n          ])\n          return model\n\n      # Compile and set up the GAN\n      generator = create_generator()\n      discriminator = create_discriminator()\n\n      discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n      # The generator is trained through the combined model where it tries to deceive the discriminator\n      combined = tf.keras.Sequential([generator, discriminator])\n      combined.compile(optimizer='adam', loss='binary_crossentropy')\n\n      def train(generator, discriminator, combined, epochs, batch_size):\n          for epoch in range(epochs):\n              # Here, you would include the steps to train your models.\n              # This typically involves generating noise, creating fake images from the noise using the generator,\n              # passing real and fake images to the discriminator, and adjusting the weights based on their performance.\n              pass\n\n      # Example of calling the train function\n      # train(generator, discriminator, combined, epochs=50, batch_size=32)`}\n</SyntaxHighlighter>\n<SyntaxHighlighter language=\"python\">\n{`import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_website(url):\n    # Send a HTTP request to the specified URL\n    response = requests.get(url)\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Parse the content of the request with BeautifulSoup\n        soup = BeautifulSoup(response.text, 'html.parser')\n        # Extract elements as needed, here we take an example of extracting all paragraph tags\n        paragraphs = soup.find_all('p')\n        for p in paragraphs:\n            print(p.text)\n    else:\n        print(\"Failed to retrieve the website\")\n\n# Example URL to scrape\nscrape_website('http://example.com')`}\n</SyntaxHighlighter>\n\n\n      <hr />\n    </main>\n  );\n}\n\nexport default DAQ;\n"],"mappings":";AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,MAAM,IAAIC,UAAU,EAAEC,SAAS,EAAEC,iBAAiB,QAAQ,cAAc;AAE/E,SAASC,GAAGA,CAAA,EAAG;EACb,oBACEL,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACEZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAI,8CAAgD,CAAC,eACrDZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAG,mWAAoW,CAAC,eACxWZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACEZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAAIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAQ,cAAoB,CAAC,kGAAkG,CAAC,eACpIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAAIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAQ,iBAAuB,CAAC,iGAAiG,CAAC,eACtIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAAIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAQ,eAAqB,CAAC,0KAA0K,CAAC,eAC7MZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAAIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAQ,WAAiB,CAAC,qGAAqG,CAAC,eACpIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAAIZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAQ,gBAAsB,CAAC,6JAA6J,CAC9L,CAAC,eACLZ,KAAA,CAAAM,aAAA,CAACF,iBAAiB;IAACS,QAAQ,EAAC,QAAQ;IAAAN,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GACnC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EACmB,CAAC,eACpBZ,KAAA,CAAAM,aAAA,CAACF,iBAAiB;IAACS,QAAQ,EAAC,QAAQ;IAAAN,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GACnC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCACmB,CAAC,eAGdZ,KAAA,CAAAM,aAAA;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAK,CACD,CAAC;AAEX;AAEA,eAAeP,GAAG","ignoreList":[]},"metadata":{},"sourceType":"module"}